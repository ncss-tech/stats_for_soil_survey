---
title: "Final Project Suggestions"
author: "Andrew G. Brown"
date: "2/11/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

0. Strongly consider using R Markdown. It is some extra stuff to learn, but well worth the  effort. Learn at least the most basic markdown syntax -- how to create code chunks, headers and do basic e.g. italics, bold etc. -- so that you can easily generate reproducible reports with R and not spin your wheels a ton trying to fix image, code or text output you pasted into MS Word. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

1. Use a standard dataset -- I suggest MT663 given that it is used in the DSM class and has some nice soil-landscape relationships contained. You can download it into your selected set using standard queries for the `2015MT663%` pedons in NASIS, or get it from the .rda file used in the course book: http://ncss-tech.github.io/stats_for_soil_survey/book/data.html#load-example-data-1

2. Once you have a `SoilProfileCollection` containing some target pedons, you can do a whole bunch with the tabular information that is contained. For the purposes of the final project, we want you to make some sort of a map, some summary statistics, and some other type of summary graphic.

   - 2.8.4 demonstrates pulling the diagnostic horizon data out of a SPC and doing some summaries -- presence/absence of features (useful for developing DSM models w/ e.g. logistic regression etc.), tabulating or cross-tabulating how many of each kind of feature, etc. The graphics at the end of this section highlight some possible comparisons of how presence absence of diagnostic features may be affected by specific landforms. http://ncss-tech.github.io/stats_for_soil_survey/book/data.html#diagnostic-features. 
   
   - The concept of "cross-tabulation" is fairly fundamental to any statistical analysis. Basically taking some sort of interaction of factors and counting up marginal frequencies or proportions. It is particularly relevant when we are dealing with the complicated hierarchical groups we typically have for soils. Understanding the composition / breakdown of members of different groups at different levels pertains to many aspects of soil classification, mapping and data analysis. The Loafercreek generalized horizon demo shows how to cross-tabulate "old" versus "new" horizon designation labels based on a prototype (such as the Official Series Description) -- but this is something that could be applied to any class concept be it based on pedon data, spatial data or otherwise. http://ncss-tech.github.io/stats_for_soil_survey/chapters/2_data/genhz_homework.html
   
   - So, you will do some sort of grouping / subset of your data. For instance based on `landform_string` or one or more of the diagnostic horizon booleans in your pedon data. Maybe you only want to focus on certain types of landforms -- compare two that are very different from one another, for instance. 
   
3. Once you have explored some aspect of tabular separation you can consider spatial locations. Then you can jump ahead to Ch 4.4 and the examples shown to view/export these pedon site point data into an `sf` object, then make interactive map, output as a shapefile/KML or other object to use in later analysis. http://ncss-tech.github.io/stats_for_soil_survey/book/spatial.html#viewing-pedon-locations

 - I would suggest making some sort of a query to SDA (Soil Data Access) using the point locations of your pedons as queries. You could then return geometry and tabular data associated with the SSURGO mapunit that each point resides in. The function that might be most useful for this is `SDA_spatialQuery` coupled with `fetchSDA_spatial` and/or some of the Web Coverage Service related tools Dylan demoed in chapter 4.
 
 - Assuming you obtain polygons of SSURGO delineations, or at least their extent, you could then use these as input to a custom analysis based on one of the many options available in 4.7: http://ncss-tech.github.io/stats_for_soil_survey/book/spatial.html#exercise-working-with-real-data _or_ most simply plug as inputs into the Region 2 Mapunit Comparison `soilReport` report http://ncss-tech.github.io/stats_for_soil_survey/book/data.html#exercise-run-mapunit-comparison
