---
title: "Pre-existing Samples in cost-constrained cLHS with the _clhs_ package"
author: "Andrew Brown"
date: "February 9, 2019"
output: html_document
---

```{r setup, include=FALSE}
set.seed(100)
knitr::opts_chunk$set(echo = TRUE, fig.retina = 2, cache = FALSE, message = FALSE, warning = FALSE)
```

First, you should understand the concepts in the __Original Demo by Dave White:__ http://ncss-tech.github.io/stats_for_soil_survey/presentations/examples/clhs.html

# Concepts

## Basics

The basic premise of the _pre-existing data_ extension to _cost-constrained_ Conditioned Latin Hypercube Sampling is that you can "force" a `clhs::clhs()` routine include an arbitrary set  of (user-defined) samples _in your final result_. That is, the set of points that it has when the number of iterations set by the user is reached. 

This replaces samples selected by the cost-cLHS algorithm -- _an equal amount to the number of existing points you have_. Be aware of this when setting `size` argument of `clhs()`

These "forced" data come at "zero-cost" because, well (at least theoretically) you _already have them_. In theory, this _very-low-cost_ partially counteracts the fact that pre-existing locations are not likely to span the environmental variable space (rasters). 

Samples can be biased in terms of the number of observations from certain kinds of areas, causing their influence to be over-represented in aggregate.

## This Demo

This demo uses the demonstration dataset prepared by Dave White. 

To simulate "existing data" a set of random samples is collected from the non-NA extent of the _RasterStack_. These are hypothetical "pre-existing data". 

Even though random samples are truly "unbiased" -- a small number of random samples are less likely to consistently span the full range of the multivariate data space (the RasterStack) when compared to a much larger sample, or exhaustive, approach to sampling.

The _RasterStack_ is regularly sampled ("exhaustively"; n=10,000) and these regular samples are passed to the cLHS algorithm for optimization to the user defined number of samples. If you are using very small cell resolutions or large rasters, you will need to adjust the number of exhaustive samples you take.

The first three cLHS routines are run using the cost raster `r.cost`, and the fourth by the classic method. `s` is default cost cLHS, `s.with.existing` is set up to retain the random samples in the last "set" of points cLHS algorithm evaluates, `s.with.cheap` uses biased existing samples and `s.classic` is the Classic cLHS set of points. Also, tabular results for "Exhaustive" sampling (regular grid) and "Population" (whole RasterStack) are included.

These observations are appended to the begining of the `all.observations` SpatialPointsDataFrame and indexed using a numeric index `1:n.existing`. The ordering and index choice is important. Note the addition of the `include` argument to the `clhs()` call that makes `s.with.existing` and `s.with.cheap`.

The final result plot shows the location of cost-constrained cLHS, with and without pre-existing samples on top of the cost raster

__WARNING:__ Use this routine your own risk. The addition to the cLHS algorithm is new and may potentially have unintended effects on clhs result. This addition was just made to the latest official release of `clhs` (was published to CRAN mid-October 2018)

# Sample Code

## Load data into RasterStack

Get the data if you need it.

```{r eval=F}
# create a new directory to store the data
dir.create("C:/workspace2/clhs", recursive = TRUE)

# setting the working directory
setwd("C:/workspace2/clhs/")

# download data
download.file(url = "http://github.com/dave-white2/data/raw/master/clhs/clhs_data.zip", destfile = "clhs.zip", method = "auto")

# unzip data
unzip(zipfile = "C:/workspace2/clhs/clhs.zip", overwrite = TRUE)
```

```{r}
library(rgdal)
library(raster)
library(clhs)

setwd("C:/workspace2/clhs/")

# load raster data of same extent and resolution
r.claymin <- raster("claymin.tif")
r.mrrtf <- raster("mrrtf.tif")
r.mrvbf <- raster("mrvbf.tif")
r.ndvi <- raster("ndvi.tif")
r.sagawi <- raster("sagawi.tif")
r.cost <- raster("cost.tif")

r.stack.cost <- stack(r.claymin,  r.mrvbf, r.ndvi, r.sagawi, r.cost)
names(r.stack.cost) <- c('claymin',  'mrvbf', 'ndvi', 'sagawi', 'cost')

# r.stack.cost <- stack(r.claymin, r.mrrtf, r.mrvbf, r.ndvi, r.sagawi, r.cost)
# names(r.stack.cost) <- c('claymin', 'mrrtf', 'mrvbf', 'ndvi', 'sagawi', 'cost')

r.stack.cost <- readAll(r.stack.cost)

r.extent.poly <- as(extent(r.stack.cost), "SpatialPolygons")

proj4string(r.extent.poly) <- proj4string(r.stack.cost)
```

## Pre-existing data

Make up some hypothetical "existing observation" locations. 

```{r}
# how many existing sample locations to simulate?
n.existing <- 10

# an equal number of cLHS samples will be generated for pre-existing 
# data runs of clhs() -- i.e. total points for all cLHS runs returned is n.existing*2

# number of cCLHS iterations
n.iter <- 10000
```

We will compare two methods.

The first method we will take a small Simple Random sample.

Then we will take a biased sample that is likely more realistic for pre-existing data. 

To do this we take a large random sample, and _order it based on cost_. Then from that large sample, we take a stratified subsample -- selected from the _cheaper half of the large random sample_.

These hoops we jump through force the pre-existing data to have somewhat _lower cost_ than is typically obtained from a small Simple Random sample. 

Of course, in practice, bias is present. It is not generally intentional. It arises through real operational constraints as well as personal (sometimes well-informed) biases about good places to sample and/or places that need to be sampled. 

cLHS only gets a raster-based view of the variablity in the landscape. It may well be that it alone cannot capture all that is "important" about a landscape. 

```{r}
# "existing data" that are truly random
# we set na.rm = TRUE so our "observations" are not in `NA` raster space
obs.existing <- sampleRandom(r.stack.cost, size = n.existing, sp=TRUE, na.rm=TRUE)

# "realistic" existing data have bias - make `obs.existing.cheap` to simulate
# we use the cost raster to bias a subsample of a random sample
obs.rnd <- sampleRandom(r.stack.cost, size = n.existing*10, sp=TRUE, na.rm=TRUE)
obs.rnd <- obs.rnd[order(obs.rnd$cost),]
biased.locations.idx <- floor(runif(n.existing, 1, length(obs.rnd$cost) / 2))
obs.existing.cheap <- obs.rnd[biased.locations.idx,]
```

## Subsample the RasterStack

Use regular sampling to lower the number of cells (see `raster::ncell()`) we are plugging into `clhs()` algorithm.

```{r}
# use regular sampling to lower the number of cells 
reg.samples <- sampleRegular(r.stack.cost, size = n.iter, sp = TRUE)
```

## Match Coordinate Reference System

Here we transform ("project") our existing data -- to ensure match the CRS of the regularly spaced subsample. We will be combining these two spatial objects for the second part of `clhs()`.

```{r}
obs.existing <- spTransform(obs.existing, CRS(proj4string(reg.samples)))
obs.existing.cheap <- spTransform(obs.existing.cheap, CRS(proj4string(reg.samples)))
```

Combine existing data with regular (sub)sample.

```{r}
all.observations <- rbind(obs.existing, reg.samples)
all.observations.cheap <- rbind(obs.existing.cheap, reg.samples)
```

Remove any records that may have `NA` cost, pending a fix in _clhs_ package.

```{r}
# pending a fix in clhs package (https://github.com/pierreroudier/clhs/issues/3)
# NA cost values must be filtered from the samples
reg.samples <- reg.samples[which(!is.na(reg.samples$cost)), ]
all.observations <- all.observations[which(!is.na(all.observations$cost)), ]
all.observations.cheap <- all.observations.cheap[which(!is.na(all.observations.cheap$cost)), ]
```

## Cost-constrained c-cLHS

Do the normal cost-constrained cLHS sampling. Same number as the existing points.

```{r}
s <- clhs(reg.samples, 
          size = n.existing*2,
          iter = n.iter,
          cost = 'cost', 
          simple = FALSE, 
          progress = FALSE)
```

Now the cost-constrained cLHS but force-include the first `r nrow(obs.existing)` row-indexes that correspond to our existing data (that we appended to the _beginning_ of `all.observations`)

```{r}
idx.to.include <-1:nrow(obs.existing)

# note we use this numeric vector of indexes later in the proof of concept
idx.to.include

s.with.existing <- clhs(all.observations, 
                        size = n.existing*2, 
                        iter = n.iter,
                        cost = 'cost', 
                        include = idx.to.include,  
                        simple = FALSE,
                        progress = FALSE)

s.with.cheap <- clhs(all.observations.cheap, 
                        size = n.existing*2, 
                        iter = n.iter,
                        cost = 'cost', 
                        include = idx.to.include,  
                        simple = FALSE,
                        progress = FALSE)
```


## Classic cLHS

For a the purposes of full comparison of methods, we will also sample using _Classic_ cLHS (without cost constraints). _These samples still have a theoretical "cost"_ -- it is just not considered in the optimization.

The Classic cLHS is important because we can see where the optimal samples would be placed _if cost were no issue_. This is the "ideal" representation.

```{r}
s.classic <- clhs(reg.samples, 
                   size = n.existing*2,
                   iter = n.iter,
                   simple = FALSE, 
                   progress = FALSE)
```

## Diagnostic plots

_cLHS_object_ diagnostic plot for normal c-cLHS. This is a custom plotting function for the result obtained when the `clhs()` `simple` argument is `FALSE`. Note that "init" refers to the source distribution and "spl" refers to the sampled distribution.

```{r fig.width=8, fig.height=4}
plot(s, mode = c("obj", "box"))
```

And... a diagnostic plot for c-cLHS _with existing data_.

```{r fig.width=8, fig.height=4}
plot(s.with.existing, mode = c("obj", "box"))
```

For the "cheap" _existing data_...

```{r fig.width=8, fig.height=4}
plot(s.with.cheap, mode = c("obj", "box"))
```

Finally, ol' reliable...

```{r fig.width=8, fig.height=4}
plot(s.classic, mode = c("obj", "box"))
```


## Spatial comparison of Methods

Create numeric vectors containing indices of the samples selected by the cost-constrained cCLHS runs and the two sets of existing samples.

```{r}
samples.idx <- s$index_samples
existing.idx <- s.with.existing$index_samples
cheap.idx <- s.with.cheap$index_samples
classic.idx <- s.classic$index_samples
```

Make a plot to show where the cLHS samples are located by the three methods (c-CLHS, c-CLHS with Simple Random pre-existing, c-CLHS with "biased" pre-existing).

Plot on an environmental variable (_SAGA Wetness Index_) and cost raster contours as a backdrop.

```{r fig.width=6, fig.height=8}
# check point locations visually (on the sagawi raster)
par(mar = c(2,2,2,2))

plot(r.sagawi)
contour(r.cost, nlevels=10, col='black', add=TRUE)

 # plot the regularly-spaced samples that were selected by classic & cost cLHS
points(reg.samples[classic.idx, ], bg = 'black', pch=8)
points(reg.samples[samples.idx, ], bg = 'red', pch=21)

# plot the regularly-spaced samples that were selected when set to retain 
# the existing points that were randomly sampled before running clhs
points(reg.samples[samples.idx, ], bg = 'red', pch=21)
points(all.observations[existing.idx, ], bg = 'blue', pch=21)
points(all.observations.cheap[cheap.idx, ], bg = 'purple', pch=21)

# overplot with crosshairs to show existing points (less colors)
points(obs.existing,  pch=3)
points(obs.existing.cheap, pch=3)

legend(x="topleft",
       legend = c("cLHS","cost-cLHS","cost-cLHS + Random","cost-cLHS + Biased","Pre-existing"),
       pch=c(8,19,19,19,3), col=c("black","red","blue","purple","black"), bg="#AAAAAA")
```

Plot the same point groups for comparison on Cost Raster itself.

```{r fig.width=6, fig.height=8}
par(mar = c(2, 2, 2, 2))

plot(r.cost)

points(reg.samples[classic.idx, ], bg = 'black', pch=8)
points(reg.samples[samples.idx, ], bg = 'red', pch=21)
points(all.observations[existing.idx, ], bg = 'blue', pch=21)
points(all.observations.cheap[cheap.idx, ], bg = 'purple', pch=21)

# overplot with crosshairs to show existing points (less colors)
points(obs.existing,  pch=3)
points(obs.existing.cheap, pch=3)

legend(x="topleft",
       legend = c("cLHS","cost-cLHS","cost-cLHS + Random","cost-cLHS + Biased","Pre-existing"),
       pch=c(8,19,19,19,3), col=c("black","red","blue","purple","black"), bg="#AAAAAA")
```

Overall, it appears that the randomly sampled existing points occur at much higher cost postitions than the vast majority of the c-cLHS points and the "cost-biased"  existing points.

The densities of red, blue and green points do appear to be _generally_ similar and clustered in the same types of areas with respect to the `sagatwi` _and_ `cost` raster.

# Proof of Concept

## Combining results for comparison

```{r}
s.all <- rbind(data.frame(method = "cost-cLHS", s$sampled_data@data),
              data.frame(method = "cost-cLHS + Random", s.with.existing$sampled_data@data),
              data.frame(method = "Random Existing", all.observations[idx.to.include, ]@data),
              data.frame(method = "cost-cLHS + Cheap", s.with.cheap$sampled_data@data),
              data.frame(method = "Cheap Existing", all.observations.cheap[idx.to.include,]@data),
              data.frame(method = "Classic cLHS", s.classic$sampled_data@data),
              data.frame(method = "Exhaustive", reg.samples@data))
s.all$method <- as.character(s.all$method)
```

```{r, echo=FALSE, message=FALSE}
library(data.table)

# # housekeeping before reshape and dcast
s.all$id <- rownames(s.all)

var.name.lut <- 1:length(names(r.stack.cost))
names(var.name.lut) <- names(s.all)[var.name.lut+1]

s.all.long <- reshape(s.all,
                      idvar="id",
                      timevar="variable",
                      v.names="value",
                      direction="long",
                      varying=2:7)

s.all.long$variable <-  names(var.name.lut)[s.all.long$variable]
s.all.long$value <- as.numeric(s.all.long$value)
s.all.long <- s.all.long[complete.cases(s.all.long),]
```

```{r eval=F}
#TODO
library(lattice)

plot(densityplot( ~ value | variable+method, layout=c(4,6), 
               data = s.all.long, 
               auto.key = list(corner = c(0.95, 0.95)), 
               scales = list(alternating=3), 
               strip = strip.custom(bg=grey(0.85))))

```

```{r}
# calculate medians for each method X variable combinations
d.mu.wide.no.cost <- dcast(s.all.long[s.all.long$variable != "cost",],
                   method ~ variable, 
                   value.var = 'value',
                   fun = median, na.rm=TRUE)

# and sum for cost of all samples in group
d.mu.wide.just.cost <- dcast(s.all.long[s.all.long$variable == "cost",],
                   method ~ variable, 
                   value.var = 'value',
                   fun=sum, na.rm=TRUE)

# THE EXISTING SAMPLES COME AT NO COST (WE HAVE THEM)
# make a column for additional cost (of the cLHS on topo of the free existing)
d.mu.wide.just.cost[,3] <- d.mu.wide.just.cost[,2]

# cheap existing - calculate additional cost for cLHS sample
d.mu.wide.just.cost[4,3] <- d.mu.wide.just.cost[4,2] - d.mu.wide.just.cost[1,2]
d.mu.wide.just.cost[1,3] <- 0

# random existing - calculate additional cost for cLHS sample
d.mu.wide.just.cost[5,3] <- d.mu.wide.just.cost[5,2] - d.mu.wide.just.cost[nrow(d.mu.wide.just.cost),3]
d.mu.wide.just.cost[nrow(d.mu.wide.just.cost),3] <- 0

total.cost <- d.mu.wide.just.cost[,2:3]
d.mu.wide <- cbind(d.mu.wide.no.cost, total.cost)
ncol <- length(names(d.mu.wide))
rownames(d.mu.wide) <- 1:nrow(d.mu.wide)
names(d.mu.wide) <- c(names(d.mu.wide.no.cost), c("total.cost", "additional.cost"))

d.mu.wide <- d.mu.wide[order(d.mu.wide[,ncol], d.mu.wide[,ncol-1]),]
```

As you can see below, the median values obtained from the different methods are quite similar. The cost is calculated as the sum of the costs for all the points in the group. Additional cost excludes the cost of existing samples.

```{r echo=FALSE}
n.obs <- data.frame(n.obs = sapply(split(s.all, f = s.all$method), nrow))

match.order.idx <- match( unique(d.mu.wide[,1]), rownames(n.obs))
d.mu.wide.nobs <- cbind(d.mu.wide, n.obs = n.obs[match.order.idx,])

# "population" summary (every cell in raster stack)
the.numbers <- c(as.numeric(apply(values(r.stack.cost), 2, median, na.rm=T)),
                 ncell(r.stack.cost), ncell(r.stack.cost))
pop.cost <- sum(values(r.stack.cost[['cost']]), na.rm=T)

the.numbers[length(the.numbers)-2] <- pop.cost
the.numbers[length(the.numbers)-1] <- pop.cost

df <- data.frame("Population", t(the.numbers), stringsAsFactors = F)
names(df) <- names(d.mu.wide.nobs)

# add population info to sample-based summary data frame
d.mu.wide.nobs <- rbind(d.mu.wide.nobs, df)

knitr::kable(d.mu.wide.nobs, 
      digits=c(4,4,4,4,4),
      row.names = FALSE,
      caption="Comparison of Sample Medians Obtained by Different cLHS Sampling Methods")
```

Both of the small "Existing" samples appear to exhibit some sort of bias relative to the Classic cLHS, Exhaustive asnd Population values. All cost-cLHS methods have a lower additional cost than Classic cLHS, but Classic cLHS is the closest to the Exhaustive and "Population" values.

Indeed, the Classic cLHS values may be more reflective of the areal abundance of some of the different variations we see in the raster space of this dataset. The Exhaustive values may be affected by the shape of the raster (non-`NA`) relative to the requested density of sampling. The "Population", similarly, is just a clipped out sample extent from a larger extent stack of rasters.

As expected, the synthetic pre-existing data generated by random sampling is the "cheapest" -- as just due to chance some of the observations are in "expensive" areas and the cLHS gets them for _free_.

This "high cost" for a pre-existing dataset might not be a _realistic_. Operational limitations or personal choices would typically have some sort of bias effect on sampling (at least _relative_ to true Simple Random Sampling). 

To counteract, or at least estimate, possible cases of this effect --- we produced a biased set of points using the cost raster as well as some random-ness. 

These biased samples show bias to certain parts of the raster space as reflected in their medians. They have a lower additional cost than a full sample set produced using cost-cLHS, but as a result they incur some bias. Comparing the values of the individual existing datasets with their corresponding cLHS group shows that the bias present in the original sample is still reflected, but to a smaller degree (i.e. direction greater or less than population/exhaustive).

## Visualizing differences between cLHS methods with nMDS

We will use _non-metric multidimensional scaling_ (nMDS) to visualize any _potential_ multivariate differences between the "optimal" samples obtained by the different methods.

```{r echo=FALSE, fig.width=7, fig.height=7}
library(cluster)
library(MASS)

# There are too many samples in the exhaustive set to show in the plot.
# TODO: similar e.g. random resampling from population v.s exhaustive?

is.exhaustive <- s.all$method == "Exhaustive"
# s.all.exhaustive <- s.all[is.exhaustive,]
# s.all.noex <- s.all[!is.exhaustive,]
# # Take 100 of them - using runif() to generate random index
# random.idx <- round(runif(n = 100, min = 1, max = nrow(s.all.exhaustive)))
# s.all.2 <- rbind(s.all.noex,  s.all.exhaustive[random.idx,])

# alternately, do not do any subsampling for population or exhaustive set
s.all.2 <- s.all[!is.exhaustive,]

# NB setting levels to preserve cost ordering
s.all.2$method <- factor(s.all.2$method, levels=unique(s.all$method))

# remove existing samples from the clhs... so we can see if holes are filled
s.all.2 <- s.all.2[-which(s.all.2$method == "cost-cLHS + Cheap")[(n.existing+1):(n.existing*2)],]
s.all.2 <- s.all.2[-which(s.all.2$method == "cost-cLHS + Random")[(n.existing+1):(n.existing*2)],]

# remove ID column 
# TODO: should the cost raster be _included_ in the dissimilarity calculations or NOT?
#       the nMDS plot looks "odd" if you leave it out
s.all.2 <- s.all.2[, !names(s.all.2) %in% c("id")]#,"cost")]

# calculate dissimilarity matrix
d.dist <- daisy(s.all.2, stand=TRUE)

# map distance matrix to 2D space via principal coordinates
d.betadisper <- vegan::betadisper(d.dist, 
                                  group=s.all.2$method, 
                                  bias.adjust = TRUE, 
                                  sqrt.dist = F, 
                                  type = 'median')

# get the scores
d.scores <- vegan::scores(d.betadisper)
# 
# # scale scores so differences are more obvious
# d.scores$sites <- d.scores$sites*3

# add contours for fixed pct of data density using KDE
s <- data.frame(x=d.scores$sites[, 1], y=d.scores$sites[, 2], .id=s.all.2$method)
s <- split(s, s$.id)

# plot
par(mar=c(1,1,3,1))
plot(d.scores$sites, type='n', axes=FALSE)
abline(h=0, v=0, lty=2, col='grey')

# http://stackoverflow.com/questions/16225530/contours-of-percentiles-on-level-plot
kdeContours <- function(i, prob, cols, m, ...) {
  
  if(nrow(i) < 2) {
    return(NULL)
  }
  
  this.id <- unique(i$.id)
  this.col <- cols[match(this.id, m)]
  dens <- kde2d(i$x, i$y, n=200); ## estimate the z counts
  
  dx <- diff(dens$x[1:2])
  dy <- diff(dens$y[1:2])
  sz <- sort(dens$z)
  c1 <- cumsum(sz) * dx * dy
  levels <- sapply(prob, function(x) {
    approx(c1, sz, xout = 1 - x)$y
  })
  
  # add contours if possibly
  if(!is.na(levels))
    contour(dens, levels=levels, drawlabels=FALSE, add=TRUE, col=this.col, ...)
  
  # # add bivariate medians
  # points(median(i$x), median(i$y), pch=3, lwd=2, col=this.col)
}

lvls <- levels(factor(s.all.2$method, exclude = "Exhaustive"))
#       "cost-cLHS","cost-cLHS (w/ Random)","cost-cLHS (w/ Biased)","Classic cLHS","Existing (Random)","Existing (Biased)"
cols <- c("RED", "BLUE", "GREEN", "BLACK", "ORANGE","PURPLE")

#vegan:::plot.betadisper(d.betadisper, ellipse = TRUE, hull = FALSE, col=cols, conf=0.5, segments=FALSE, xlab='', ylab='', main='', sub='', las=1)

res <- lapply(s, kdeContours, prob=c(0.75), cols=cols, m=lvls, lwd=2, lty=3)
# res <- lapply(s, kdeContours, prob=c(0.95), cols=cols, m=lvls, lwd=1, lty=3)

# add individual sample points
points(d.scores$sites, cex=0.6, col=cols[match(d.mu.wide$method, lvls)], pch=16)

vegan::ordilabel(d.betadisper, 
                display='centroids',
                fill=NA, border=0,
                col=cols[as.numeric(d.mu.wide$method)])

title('Ordination of cLHS Samples by various methods\n75% Density Contours')

box()
```

This _nMDS_ graphic, though apparently complicated, corroborates the intuition we might have about the effects of including existing, non-optimal data. 

We _omitted the cost raster from the ordination routine_, so that the separations we are seeing are due to true variation in the environment interaction with the different algorithms handling of cost.

We wrap each group's nMDS score point cloud with a 50% (median) density contour so we can view its central tendency more easily.

When projected onto a 2D surface (the plot) the outline of the group hypervolumes appear to be similar, as shown by the similarities (proximity) of their 50% density contour. All groups are spanning a wide range on the X-axis, but are offset on the Y axis.

If we consider the Classic cLHS to be the (in practice typically unachievable for Soil Survey) "gold standard", then we can consider any offset from that Classic cLHS point cloud to be bias due to our method.

Is the Classic cLHS picking up on variation in the landscape that the cost-cLHS methods see as "too costly?" 

_That is how I would interpret this graphic._ 

The _cost-constrained_ results are offset substantially on the vertical axis from the _Classic_.

The two clouds of _Existing_ (Cheap & Random) data plot near the origin. The "forced" inclusion of the existing data biases the _cost-cLHS_ in the direction of the _Existing_... and the cost-cLHS that use those existing data are _farther still_ from the "optimal" _Classic cLHS_! In the case where your existing data are not _Random_ but rather are are _Cheap_ (low-hanging-fruit) the offset from _Classic cLHS_ is even greater.

This would suggest, as expected, that additional bias is introduced to cLHS by additional constraints on _Classic cLHS_ method. The degree of bias in the existing data you force-include in _cost-constrained cLHS_ will impact the deviation from the ideal. These differences seen in the nMDS may be essentially numerical noise -- given the precision/accuracy of input raster data and the scaling that occurs during the nMDS process.

Future work will try to re-state differences in cLHS in more practical terms. Further, the `clhs()` code will be reviewed to determine if there is a better way to make use of the information in prior data.

__Food for thought:__ Is the decrease in cost -- i.e. making a project feasible v.s. not -- sufficient to warrant increased bias?

_Should the cost raster be included in the ordination?_
